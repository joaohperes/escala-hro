# Medical Schedule Dashboard - Comprehensive System Analysis
## Hospital Regional do Oeste (HRO) - Escala MÃ©dica

---

## EXECUTIVE SUMMARY

This is a sophisticated medical scheduling dashboard system with an automated daily update pipeline. The project demonstrates evolution from a script-based generation approach to a hybrid manual/automated system with **critical architectural tensions** that need resolution.

### Current Status
- **Main Dashboard**: `index.html` (2,599 lines, ~164 KB)
- **Latest Commit**: "Atualizar dashboard - 08/11/2025 10:48:20"
- **Data Sources**: 4 JSON files + 2 temporary extraction files
- **Automation**: 2 GitHub Actions workflows running daily

### Key Finding
**A critical mismatch exists between what the workflow expects and what actually exists:**
- Workflow calls `converter_inteligente.py` â†’ File does not exist
- System relies on rolling window logic â†’ Lives in temporary files (`/tmp/`)
- Multiple HTML files with unclear ownership â†’ Version conflicts likely

---

## PART 1: FILE STRUCTURE & PURPOSES

### 1.1 Core Dashboard Files

#### **index.html** (Main Entry Point) - 2,599 lines
**Purpose**: Live dashboard published to GitHub Pages
**Content**:
- Dark theme interface with HRO branding
- Embedded authentication system
- Two-day schedule view (Today + Previous Day)
- Professional search, sector grouping, turno classification
- Modal dialogs (Contacts, Extensions)

**Key Data Objects**:
```javascript
const escalas = {
    "atual": { data, registros[], total },
    "anterior": { data, registros[], total },
    "data_atualizacao": "DD/MM/YYYY",
    "hora_atualizacao": "HH:MM",
    "status_atualizacao": "sucesso"
}
const profissionaisData = { professionals[] }
const ramaisData = { departments[] }
```

**Problem**: This file is manually edited but also a workflow target (line 55 of atualizar-dashboard.yml)

---

#### **dashboard_final.html** (Documentation Artifact) - 1,386 lines
**Purpose**: Documented "single source of truth" for the dashboard
**Status**: Reference implementation with inline documentation
**Critical Issue**: This is NOT the published version; `index.html` is

**From README_DASHBOARD.md**:
> "Este Ã© o arquivo HTML **FINAL e COMPLETO** do dashboard"

But workflow updates `index.html`, not this file.

---

#### **dashboard_executivo.html** (Generated Output) - 1,724 lines
**Purpose**: Temporary output file from Python generator scripts
**Generated By**: `gerar_dashboard_executivo.py` â†’ saves to `/tmp/dashboard_executivo.html`
**Role in Workflow**: Never committed, used as intermediate file

---

### 1.2 Data Source Files

#### **escalas_multiplos_dias.json** (27.7 KB)
**Purpose**: Fallback/historical schedule data
**Last Update**: 03/11/2025
**Structure**:
```json
{
  "atual": {
    "data": "03 novembro 2025",
    "data_simples": "03/11/2025",
    "registros": [
      {
        "profissional": "Name",
        "setor": "Sector Name",
        "tipo_turno": "Turno Type",
        "horario": "HH:MM/HH:MM"
      }
    ]
  },
  "anterior": { ... }
}
```

#### **ramais_hro.json** (13 KB)
**Purpose**: Hospital extension directory with 100+ departments
**Structure**:
```json
{
  "departments": [
    {
      "name": "Department Name",
      "extensions": ["1234", "5678"]
    }
  ]
}
```

#### **profissionais_autenticacao.json** (19.3 KB)
**Purpose**: Professional contact list for login & authentication
**Contains**: ~100 professionals with email, phone, last4 digits
**Critical**: Used for authentication, must stay in sync with escalas data

#### **setor_ramais_mapping.json** (5.3 KB)
**Purpose**: Maps dashboard sectors to hospital departments/extensions
**Reason**: Sector names in schedule don't match ramais department names
**Example**: "Alojamento Conjunto" â†’ "Maternidade - CoordenaÃ§Ã£o"

---

### 1.3 Temporary/Working Files

#### **/tmp/extracao_inteligente.json** (50 KB)
**Created By**: `extracao_inteligente.py`
**Contains**: Today's extraction + previous day's data (rolling window)
**Lifetime**: Recreated daily by extraction script
**Consumer**: `gerar_dashboard_executivo.py` reads this

#### **/tmp/extracao_inteligente_anterior.json** (50 KB)
**Created By**: `extracao_inteligente.py` (at end of extraction)
**Contains**: Today's data as backup
**Purpose**: Used NEXT day as the "anterior" (rolling window mechanism)
**Critical**: If lost, "Dia Anterior" functionality breaks next day

#### **/tmp/dashboard_executivo.html** (163 KB)
**Created By**: `gerar_dashboard_executivo.py`
**Purpose**: Generated dashboard used by workflow to update `index.html`
**Note**: Deleted/recreated on each update

---

### 1.4 Script Files

#### **extracao_inteligente.py** (517 lines) â˜… CRITICAL
**Purpose**: Extract schedule data from escala.med.br via Selenium
**Triggers**: 
- GitHub Action: `atualizar-dashboard.yml` (daily 07:01 BrasÃ­lia)
- Manual: `python3 extracao_inteligente.py`

**Process**:
1. Selenium headless Chrome â†’ logs in to escala.med.br
2. Extracts via JavaScript (X-coordinate based sector detection)
3. Saves to `/tmp/extracao_inteligente.json`
4. **Rolling Window**: Loads previous extraction from `/tmp/extracao_inteligente_anterior.json`
5. Creates backup for next day

**Fallback Selectors**: Multiple CSS selector strategies for robustness

**Critical Line 443**: `arquivo_anterior = '/tmp/extracao_inteligente_anterior.json'`

---

#### **gerar_dashboard_executivo.py** (3,211 lines) â˜… VERY LARGE
**Purpose**: Generate HTML dashboard from extraction JSON
**Input Sources** (in order):
1. `/tmp/extracao_inteligente.json` (today's extraction)
2. Fallback: `/Users/joaoperes/escalaHRO/escalas_multiplos_dias.json`
3. Fallback: `profissionaisData` hardcoded in generated HTML

**Output**: `/tmp/dashboard_executivo.html` (163 KB generated file)

**Key Functions**:
- `obter_tipo_turno()`: Classify shift type (matutino, vespertino, noturno, etc.)
- Badge color assignment
- Sector organization & grouping
- Professional search functionality
- Responsive layout generation

**Problem**: 3,200+ lines of Python to generate HTML. Fragile, hard to debug.

---

#### **update_dashboard.py** (90 lines)
**Purpose**: Orchestration script that runs extraction then generation
**Workflow**:
1. Call `extracao_inteligente.py` â†’ gets `/tmp/extracao_inteligente.json`
2. Call `gerar_dashboard_executivo.py` â†’ generates `/tmp/dashboard_executivo.html`
3. Return 0 if successful

**Used By**: `daily-escala.yml` workflow

---

#### **update_escala_data_only.py** (95 lines) â˜… IMPORTANT
**Purpose**: Update ONLY the JSON data in HTML, preserving code
**Input**: `/tmp/extracao_inteligente.json`
**Output**: Overwrites both `index.html` and `docs/index.html`

**Mechanism**:
```python
pattern = r'const escalas = \{.*?\};'
replacement = f'const escalas = {escalas_json_str};'
```

**Problem**: Uses regex to find/replace JSON in minified HTML - fragile if formatting changes

---

#### **fix_previous_day.py** (96 lines)
**Purpose**: Manual correction of "Dia Anterior" data
**Method**: Uses git to retrieve previous commit's data
**Hardcoded**: Commit hash "9055118" (05/11 commit)
**When Needed**: Only if rolling window mechanism fails

---

#### **extract_ramais_pdf.py** (118 lines)
**Purpose**: Extract ramais from hospital PDF document
**Status**: Not currently used in automated workflow
**Output**: Could generate `ramais_hro.json`

---

#### **publicar_notion.py** (229 lines)
**Purpose**: Publish schedule to Notion database
**Status**: Not integrated into GitHub Actions
**Dependencies**: notion-client library

---

### 1.5 Configuration Files

#### **requirements.txt**
```
selenium
webdriver-manager
```

#### **.env** (not in repo)
Contains:
- `ESCALA_USERNAME`: Login for escala.med.br
- `ESCALA_PASSWORD`: Login password

#### **.env.example** (in repo)
Template showing required variables

---

## PART 2: DATA FLOW ARCHITECTURE

### 2.1 Daily Update Flow (Automated)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    GITHUB ACTIONS WORKFLOW                       â”‚
â”‚              atualizar-dashboard.yml (Daily 07:01)              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
                   [Setup Python 3.11]
                              â†“
                   [Install Chrome + Selenium]
                              â†“
    â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
    â•‘  extracao_inteligente.py (Extraction)                     â•‘
    â•‘  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                    â•‘
    â•‘  1. Login to escala.med.br                                â•‘
    â•‘  2. Extract today's schedule via JavaScript               â•‘
    â•‘  3. Load /tmp/extracao_inteligente_anterior.json           â•‘
    â•‘     â†“ (becomes "anterior")                                â•‘
    â•‘  4. Save to /tmp/extracao_inteligente.json                 â•‘
    â•‘     â”œâ”€ "atual": Today's 90+ professionals                 â•‘
    â•‘     â”œâ”€ "anterior": Yesterday's 90+ professionals          â•‘
    â•‘     â””â”€ metadata: timestamps, status                       â•‘
    â•‘  5. Create backup: /tmp/extracao_inteligente_anterior.json â•‘
    â•‘     â””â”€ Ready for tomorrow's "anterior"                    â•‘
    â•‘  [continue-on-error: true]                                â•‘
    â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                              â†“
    â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
    â•‘  converter_inteligente.py (??? - FILE DOESN'T EXIST)      â•‘
    â•‘  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                    â•‘
    â•‘  [MISSING - WORKFLOW EXPECTS IT]                          â•‘
    â•‘  [continue-on-error: true]                                â•‘
    â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                              â†“
    â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
    â•‘  Manual Dashboard (NOT REGENERATED)                        â•‘
    â•‘  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                        â•‘
    â•‘  index.html stays as-is                                   â•‘
    â•‘  (Dashboard was manually crafted, not auto-generated)     â•‘
    â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                              â†“
    â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
    â•‘  Git Commit & Push                                         â•‘
    â•‘  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                        â•‘
    â•‘  if [ index.html changed ]                                â•‘
    â•‘    commit -m "âœ… Dashboard atualizado..."                 â•‘
    â•‘    push to origin main                                    â•‘
    â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

### 2.2 Alternative Flow (daily-escala.yml)

```
daily-escala.yml (Daily 07:00 - runs 1 minute BEFORE atualizar-dashboard.yml)
    â†“
update_dashboard.py
    â”œâ”€ extracao_inteligente.py â†’ /tmp/extracao_inteligente.json
    â””â”€ gerar_dashboard_executivo.py â†’ /tmp/dashboard_executivo.html
    â†“
[Copy /tmp/dashboard_executivo.html â†’ index.html]
    â†“
git commit + push
```

### 2.3 Data Transformation Pipeline

```
escala.med.br (Source)
    â†“ [Selenium extraction]
/tmp/extracao_inteligente.json
    â”œâ”€ {"atual": {...}, "anterior": {...}}
    â”œâ”€ Professionalsdata: 90+ names, sectors, turno types, times
    â”œâ”€ Rolling window: "anterior" from yesterday's backup
    â”œâ”€ Timestamps, status
    â””â”€ Python JSON format
    â†“
[Option A] gerar_dashboard_executivo.py (Python generation)
    â”œâ”€ Read extraction JSON
    â”œâ”€ Read profissionaisData, ramaisData (hardcoded)
    â”œâ”€ Classify turnos (matutino, vespertino, noturno, diurno, etc.)
    â”œâ”€ Generate 3,200-line HTML
    â””â”€ Write to /tmp/dashboard_executivo.html
    â†“
index.html (Published Dashboard)
    â”œâ”€ Dark theme UI
    â”œâ”€ Embedded authentication
    â”œâ”€ Professional search & filtering
    â”œâ”€ Sector organization
    â””â”€ Modal dialogs
    â†“
[GitHub Pages] â†’ https://joaoperes.github.io/escalaHRO/

[Option B] update_escala_data_only.py (Data injection)
    â”œâ”€ Read /tmp/extracao_inteligente.json
    â”œâ”€ Find "const escalas = {...}" in index.html
    â”œâ”€ Replace ONLY the JSON content
    â”œâ”€ Keep all JavaScript code intact
    â””â”€ Write back to index.html
```

---

## PART 3: WORKFLOW AUTOMATION

### 3.1 GitHub Actions: atualizar-dashboard.yml

**Trigger**: `0 10 * * *` (Daily 10:00 UTC = 07:00 BrasÃ­lia)

**Steps**:
1. âœ… Checkout code
2. âœ… Setup Python 3.11
3. âœ… Install Chrome + Selenium
4. âœ… Run `extracao_inteligente.py` â†’ `/tmp/extracao_inteligente.json`
5. âš ï¸  Run `converter_inteligente.py` â†’ **FILE DOESN'T EXIST**
6. âŒ Skip regeneration (commented out: "Dashboard gerado manualmente")
7. âœ… Commit & Push index.html (if changed)
8. ðŸ“‹ Upload logs on failure

**Problems**:
- Step 5 will fail silently (`continue-on-error: true`)
- Step 6 is intentionally skipped (by design)
- Only useful if manual updates happen between 07:01-10:00

---

### 3.2 GitHub Actions: daily-escala.yml

**Trigger**: `0 10 * * *` (Daily 10:00 UTC = 07:00 BrasÃ­lia)
**Runs**: 1 minute BEFORE atualizar-dashboard.yml (same cron = race condition!)

**Steps**:
1. âœ… Checkout code
2. âœ… Setup Python 3.11
3. âœ… Install Chrome + Selenium
4. âœ… Run `update_dashboard.py` which:
   - Calls `extracao_inteligente.py` â†’ `/tmp/extracao_inteligente.json`
   - Calls `gerar_dashboard_executivo.py` â†’ `/tmp/dashboard_executivo.html`
5. âœ… Copy `/tmp/dashboard_executivo.html` â†’ `index.html`
6. âœ… Commit & Push index.html
7. ðŸ“‹ Upload error screenshots

**Problems**:
- **RACE CONDITION**: Both workflows run at same time!
- Both workflows update `index.html` simultaneously
- Commit ordering unpredictable
- Which version wins is unclear

---

### 3.3 Workflow Conflict Analysis

#### **Timing Issue**:
```
GitHub Actions Scheduler (10:00 UTC daily):
â”œâ”€ daily-escala.yml starts        (run 1 of N)
â”‚  â”œâ”€ extracao_inteligente.py
â”‚  â”œâ”€ gerar_dashboard_executivo.py (generates HTML)
â”‚  â”œâ”€ index.html updated (generated)
â”‚  â””â”€ git push (commit generated HTML)
â”‚
â””â”€ atualizar-dashboard.yml starts  (run 1 of M)  [SAME TIME]
   â”œâ”€ extracao_inteligente.py (overwrites /tmp/extracao_inteligente.json)
   â”œâ”€ converter_inteligente.py (fails)
   â””â”€ git push (commits extraction results? or nothing?)
```

#### **Outcome**:
- If daily-escala finishes first: Generated HTML is published, then atualizar-dashboard pushes nothing
- If atualizar-dashboard finishes first: Maybe extraction is wasted
- If they overlap: Git push conflicts (one will fail)

---

## PART 4: ROLLING WINDOW LOGIC (Dia Anterior)

### 4.1 How It Works

**Goal**: Always show today's schedule + yesterday's schedule in dashboard

**Mechanism**:
```
Day 1: Extract Nov 5
    â†“
    â”‚  /tmp/extracao_inteligente.json
    â”‚  {
    â”‚    "atual": {Nov 5 data},
    â”‚    "anterior": {empty - first run}
    â”‚  }
    â”‚
    â””â”€â†’ Backup: /tmp/extracao_inteligente_anterior.json
        {Nov 5 data - for tomorrow}

Day 2: Extract Nov 6
    â†“
    â”‚  Load /tmp/extracao_inteligente_anterior.json
    â”‚  (Contains Nov 5 data from backup)
    â”‚
    â””â”€â†’ /tmp/extracao_inteligente.json
        {
          "atual": {Nov 6 data},
          "anterior": {Nov 5 data} âœ… Automatically!
        }
    
    â””â”€â†’ Backup: /tmp/extracao_inteligente_anterior.json
        {Nov 6 data - for tomorrow}

Day 3: Extract Nov 7
    â†“
    â””â”€â†’ /tmp/extracao_inteligente.json
        {
          "atual": {Nov 7 data},
          "anterior": {Nov 6 data} âœ… Automatic!
        }
```

### 4.2 Critical Dependency Chain

```
Rolling Window Success depends on:
1. /tmp/extracao_inteligente_anterior.json exists
2. Contains valid JSON from previous day
3. File persists between daily runs (GitHub Actions)
4. extracao_inteligente.py reads it every day
5. extracao_inteligente.py overwrites it at end of day
```

### 4.3 Failure Scenarios

#### **Scenario 1: File doesn't exist (first run)**
```python
# extracao_inteligente.py line 446-459
if os.path.exists(arquivo_anterior):
    # Load it
else:
    # Create empty
    resultado_anterior_salvo = None
    # Later, create empty anterior
```
**Result**: First day has empty "Dia Anterior" âœ“ (handled)

#### **Scenario 2: File lost between runs**
```
Day 1: Runs successfully, creates /tmp/extracao_inteligente_anterior.json
Day 2: File is missing (GitHub Actions /tmp cleanup? restart?)
       â†’ No arquivo_anterior found
       â†’ Empty "anterior" created
       â†’ Dashboard shows only today
```
**Result**: "Dia Anterior" broken for that day âœ—

#### **Scenario 3: GitHub Actions runner reset**
```
If GitHub Actions switches runners between executions:
- /tmp files are ephemeral
- Different runner = different /tmp
- Rolling window chain breaks
```
**Status**: This is THE MAJOR RISK

---

## PART 5: POTENTIAL POINTS OF FAILURE

### 5.1 Critical Issues (High Risk)

#### **Issue 1: Missing converter_inteligente.py**
- **Severity**: HIGH
- **Impact**: Workflow fails on line 43, commits nothing
- **Detection**: Check if file exists in repo
- **Fix**: Create dummy script or remove from workflow

#### **Issue 2: Race Condition - Two Workflows**
- **Severity**: HIGH
- **Impact**: Git push conflicts, unpredictable results
- **When**: Both workflows run at 10:00 UTC daily
- **Detection**: Check recent commit history for interleaved pushes
- **Fix**: Disable one workflow or adjust timing

#### **Issue 3: Temporary Files Are Ephemeral**
- **Severity**: CRITICAL
- **Impact**: Rolling window fails if /tmp is cleared
- **When**: Between GitHub Actions runs, runner restart
- **Problem**: `/tmp/extracao_inteligente_anterior.json` is not committed
- **Fix**: Commit these files to repo OR implement git-based rolling window

#### **Issue 4: Multiple HTML Files**
- **Severity**: MEDIUM
- **Impact**: Version conflicts, unclear which is authoritative
- **Files**: `index.html`, `dashboard_final.html`, `dashboard_executivo.html`
- **Status**: 
  - `index.html` = published (2,599 lines)
  - `dashboard_final.html` = documented reference (1,386 lines)
  - `dashboard_executivo.html` = generated artifact (1,724 lines)
- **Problem**: Which should be edited? Which is source of truth?
- **Risk**: Manual edits to `index.html` might be overwritten by workflow

#### **Issue 5: 3,200-Line Python Generator**
- **Severity**: MEDIUM
- **Impact**: Hard to maintain, debug, modify
- **Files**: `gerar_dashboard_executivo.py` (3,211 lines!)
- **Problem**: Generates complex HTML from scratch each time
- **Alternative**: `update_escala_data_only.py` is better (95 lines)

---

### 5.2 Data Consistency Issues

#### **Issue 6: Multiple Data Sources**
- **Severity**: MEDIUM
- **Conflicts**:
  - `escalas_multiplos_dias.json` (hardcoded)
  - `/tmp/extracao_inteligente.json` (daily from extraction)
  - `profissionaisData` (hardcoded in HTML)
  - `ramaisData` (hardcoded in HTML)
- **Problem**: Which is current? Fallback order unclear
- **Example**: Professional added to one source but not another

#### **Issue 7: Sector-Ramais Mapping**
- **Severity**: LOW-MEDIUM
- **File**: `setor_ramais_mapping.json` (mapping table)
- **Problem**: Manual mapping gets out of sync with actual sectors
- **Current**: 46 sectors mapped to 30+ departments
- **Risk**: New sectors added to schedule but not mapped

#### **Issue 8: Professional Authentication**
- **Severity**: MEDIUM
- **Dependency**: `profissionaisData` must match escalas
- **Risk**: Professional added to schedule but not to authentication
- **Result**: They can't login to see their shifts
- **File**: Embedded in `index.html`, no sync mechanism

---

### 5.3 Workflow Issues

#### **Issue 9: continue-on-error: true Everywhere**
- **Severity**: MEDIUM
- **Problem**: Failures are silently ignored
- **Impact**:
  - Extraction fails â†’ commit nothing â†’ undetected
  - Converter fails â†’ commit nothing â†’ undetected
  - No alerting if something breaks
- **Current**: Lines 39, 44, 58 in atualizar-dashboard.yml

#### **Issue 10: No Validation Step**
- **Severity**: MEDIUM
- **Problem**: Generated HTML is not tested
- **Missing**:
  - JSON syntax validation
  - Professionals count verification
  - Essential element checks (search, modals, login)
- **Risk**: Corrupted HTML published to GitHub Pages

#### **Issue 11: Hardcoded Credentials**
- **Severity**: MEDIUM
- **Problem**: `.env` file not in repo
- **Risk**: Each developer needs to create `.env` manually
- **When running**: If `.env` missing, extraction fails silently
- **Better**: Use GitHub Secrets (which it does), but needs verification

---

### 5.4 Data Loss Risks

#### **Issue 12: "Dia Anterior" Can Be Lost**
- **Severity**: HIGH
- **Scenario 1**: `/tmp/extracao_inteligente_anterior.json` deleted
  - Next extraction has no previous day data
  - Creates empty "anterior"
  - Dashboard shows only today
- **Scenario 2**: Manual fixes (like fix_previous_day.py) git the wrong commit
  - Hardcoded hash "9055118" becomes stale
  - Eventually invalid

#### **Issue 13: Overwriting Without Backup**
- **Severity**: MEDIUM
- **Problem**: `update_escala_data_only.py` regex replaces JSON
- **Risk**:
  - If regex pattern changes (minification)
  - If JSON structure changes
  - Replacement fails silently
  - Old data remains in HTML

---

## PART 6: CURRENT WORKFLOW STATUS

### 6.1 What Actually Works

âœ… **Extraction**: `extracao_inteligente.py` successfully extracts from escala.med.br
âœ… **Rolling Window**: `anterior` logic properly maintains yesterday's data
âœ… **Dashboard Display**: HTML/CSS/JS properly displays schedule
âœ… **Authentication**: Login system works (tested with last4 digits)
âœ… **Responsive**: Mobile and desktop views work
âœ… **Search/Filters**: Professional search, sector grouping functional

### 6.2 What's Broken or Unused

âŒ **converter_inteligente.py**: File doesn't exist, workflow fails on it
âŒ **Race Condition**: Two workflows run simultaneously
âš ï¸  **Generator Script**: `gerar_dashboard_executivo.py` not used by primary workflow
âš ï¸  **Alternative Flow**: `daily-escala.yml` conflicts with `atualizar-dashboard.yml`
âš ï¸  **Notion Publishing**: `publicar_notion.py` not integrated
âš ï¸  **PDF Extraction**: `extract_ramais_pdf.py` manual only, not automated

### 6.3 Recent Commits (Last 30 days)

```
23e27bb Atualizar dashboard - 08/11/2025 10:48:20
9eb192a fix: Remove border-bottom line from turno-title
9e6b266 style: Add circular badge with count to turno titles
c640972 refactor: Simplify card layout - remove redundant Turno field
a189328 fix: Add 'vesp' abbreviation detection for MISTO badge

107634b fix: Restore easter-egg and fix header mobile alignment
21f6a4f Resolve merge conflict - keep our version with all features
a2f97b8 fix: Disable automatic dashboard generation to preserve manual updates
```

**Pattern**: Manual fixes + style updates, NOT automated generation

---

## PART 7: RECOMMENDED ACTIONS

### 7.1 Immediate (Fix Critical Issues)

**Action 1**: Remove or create `converter_inteligente.py`
```bash
# Option A: Create dummy
echo '#!/usr/bin/env python3
# Placeholder - no conversion needed
print("âœ“ Conversion skipped - using manual dashboard")
' > /Users/joaoperes/escalaHRO/converter_inteligente.py

# Option B: Remove from workflow
# Delete line 43-44 from atualizar-dashboard.yml
```

**Action 2**: Consolidate workflows
```bash
# Option 1: Keep only daily-escala.yml (generates + commits)
#   Delete atualizar-dashboard.yml

# Option 2: Keep only atualizar-dashboard.yml + fix it
#   Delete daily-escala.yml
#   Fix atualizar-dashboard to actually update dashboard
```

**Action 3**: Commit rolling window backup files
```bash
# Problem: /tmp files lost on runner restart
# Solution: Either
#   A) Commit .json files to repo (in data/ folder)
#   B) Use git-based rolling window (read from git history)
#   C) Accept daily loss and recreate from git
```

---

### 7.2 Short-term (Stabilize System)

**Action 4**: Document the single source of truth
```bash
# Clarify: Is it index.html or dashboard_final.html?
# Current state: index.html is published, dashboard_final.html is documented
# Recommendation: Keep index.html as primary, remove dashboard_final.html
```

**Action 5**: Create comprehensive data pipeline documentation
```
Create file: DATA_PIPELINE.md
â”œâ”€â”€ Data sources (what feeds what)
â”œâ”€â”€ Transformation steps
â”œâ”€â”€ Fallback order
â”œâ”€â”€ Validation rules
â””â”€â”€ Recovery procedures
```

**Action 6**: Add validation & monitoring
```python
# Create: validate_dashboard.py
# Check:
# 1. JSON syntax valid
# 2. Professional count > 0
# 3. Sectors populated
# 4. Search functionality works
# 5. All required fields present
```

---

### 7.3 Medium-term (Improve Maintainability)

**Action 7**: Replace 3,200-line generator with data-injection approach
```
Current: gerar_dashboard_executivo.py (3,211 lines)
Better: update_escala_data_only.py approach (95 lines)

Instead of regenerating HTML:
1. Maintain stable HTML template in repo
2. Only update const escalas = {...} in daily workflow
3. Reduces code complexity dramatically
```

**Action 8**: Implement git-based rolling window
```python
# Instead of /tmp files:
# 1. Use git to get yesterday's commit
# 2. Extract data from previous version
# 3. More reliable, no /tmp dependency
# 4. Self-documenting (versioned data)
```

**Action 9**: Add comprehensive error alerting
```bash
# Current: continue-on-error: true (silently fail)
# Better: Slack/email notifications on failure
# Add validation checks before commit
# Only push if validation passes
```

---

### 7.4 Long-term (Architecture Improvement)

**Architecture Evolution**:
```
Current State (Manual + Auto, Conflicted):
â”œâ”€ Manual: Edit index.html directly
â”œâ”€ Auto: Workflows generate & commit
â””â”€ Conflict: Both paths update same file

Better State (Data-Driven):
â”œâ”€ Single HTML template (stable, versioned)
â”œâ”€ Daily extraction (automated, robust)
â”œâ”€ Data injection (simple, safe, fast)
â””â”€ Git history = automatic rolling window

Even Better (Decoupled):
â”œâ”€ Backend API (extraction + data service)
â”œâ”€ Frontend SPA (React/Vue, pulls from API)
â”œâ”€ Admin dashboard (manage professionals, sectors)
â””â”€ Mobile apps possible
```

---

## SUMMARY TABLE: Files & Responsibilities

| File | Purpose | Status | Updated By | Risk |
|------|---------|--------|-----------|------|
| index.html | Published dashboard | Working | Manual + Workflow? | Medium |
| dashboard_final.html | Documented reference | Static | Documentation | Low |
| dashboard_executivo.html | Generated output | Working | gerar_dashboard... | Low |
| escalas_multiplos_dias.json | Fallback data | Stale | Manual only | Medium |
| ramais_hro.json | Extensions directory | Current | Manual only | Low |
| profissionais_autenticacao.json | Authentication + contacts | Current | Manual only | Medium |
| setor_ramais_mapping.json | Sector-department mapping | Current | Manual only | Low |
| /tmp/extracao_inteligente.json | Daily extraction | Fresh | extracao_inteligente.py | High |
| /tmp/extracao_inteligente_anterior.json | Rolling window backup | Fresh | extracao_inteligente.py | Critical |
| extracao_inteligente.py | Extract from web | Robust | Manual only | Low |
| gerar_dashboard_executivo.py | Generate HTML | Works but unused | Manual only | Medium |
| update_escala_data_only.py | Update data in HTML | Available | Manual only | Low |
| update_dashboard.py | Orchestration | Available | Workflow | Low |
| atualizar-dashboard.yml | Daily workflow | Broken | Manual | High |
| daily-escala.yml | Alternative workflow | Works | Manual | Medium |

---

## CONCLUSION

This is a **mature but fragile system** with the right components but poor orchestration.

**Strengths**:
- Sophisticated extraction logic (X-coordinate based sector detection)
- Elegant rolling window implementation
- Feature-rich dashboard UI
- Good fallback strategies

**Weaknesses**:
- Two conflicting workflows running simultaneously
- Missing file referenced in workflow (converter_inteligente.py)
- Critical data in /tmp (ephemeral, not version controlled)
- Unclear which is source of truth (3 HTML files)
- 3,200-line generator when 95-line injector exists
- No validation or monitoring
- Silent failures (continue-on-error: true everywhere)

**Recommended Path Forward**:
1. Fix immediate issues (converter, race condition, temp files)
2. Stabilize workflows (single, tested, monitored)
3. Simplify generation (data injection instead of full regeneration)
4. Improve robustness (validation, alerting, recovery procedures)

**Estimated effort**: 
- Immediate fixes: 1-2 hours
- Short-term stabilization: 4-6 hours
- Medium-term improvements: 8-12 hours
- Long-term architecture: 20-40 hours (optional)

